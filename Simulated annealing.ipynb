{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Annealing for Tetris Optimization\n",
    "\n",
    "Simulated Annealing (SA) is one of the simplest and best-known meta-heuristic method for addressing the difficult black box global optimization problems (those whose objective function is not explicitly given and can only be evaluated via some costly computer simulation). It is massively used on real-life applications.\n",
    "\n",
    "The main advantage of SA is its simplicity. SA is based on an analogy with the physical annealing of materials that avoids the drawback of the Monte-Carlo approach (which can be trapped in local minima), thanks to an efficient Metropolis acceptance criterion.\n",
    "\n",
    "\n",
    "The SA algorithm is describes as follows:\n",
    "- Firstly, we select an initial state s0 which will be the current solution of our problem.\n",
    "- Then, for each iteration : \n",
    "    - We select a neighbour of this point following a known distribution of probability (in our case a normal distribution).\n",
    "    - We compare the objective functions of both points.\n",
    "    - The neighbour becomes a the current solution with the following probability of acceptance: \n",
    "\n",
    "\\begin{cases}\n",
    "    1 & \\text{if } f(j) < f(i) \\\\\n",
    "    e^{\\frac{f(i)-f(j)}{c}} & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\n",
    "j being the neighbour, i the current solution and f the objective function (-score in our case).\n",
    "\n",
    "Here is an implementation of the SA algorithm applied to learning Tetris.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "import os\n",
    "os.chdir('C:/Users/USER/Desktop/Tetris/learning_tetris/game_code')\n",
    "from game_simulation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Average score : 0.0\n",
      "Iteration 2: Average score : 0.0\n",
      "Iteration 3: Average score : 0.0\n",
      "Iteration 4: Average score : 0.0\n",
      "Iteration 5: Average score : 0.1\n",
      "Iteration 6: Average score : 0.2\n",
      "Iteration 7: Average score : 0.0\n",
      "Iteration 8: Average score : 0.0\n",
      "Iteration 9: Average score : 0.0\n",
      "Iteration 10: Average score : 0.0\n",
      "Iteration 11: Average score : 0.1\n",
      "Iteration 12: Average score : 0.0\n",
      "Iteration 13: Average score : 0.0\n",
      "Iteration 14: Average score : 0.0\n",
      "Iteration 15: Average score : 0.0\n",
      "Iteration 16: Average score : 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: Average score : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, learning_curve[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m learning_curve\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msimulation_SA\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m)  \n",
      "Cell \u001b[1;32mIn[10], line 23\u001b[0m, in \u001b[0;36msimulation_SA\u001b[1;34m(N_iteration, step_size, temp)\u001b[0m\n\u001b[0;32m     21\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m     test_scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43msimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms0\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m learning_curve\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(test_scores))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: Average score : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, learning_curve[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\Desktop\\Tetris\\learning_tetris\\game_code\\game_simulation.py:98\u001b[0m, in \u001b[0;36msimulation\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m     96\u001b[0m game\u001b[38;5;241m.\u001b[39mnew_figure(\u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m col, rot \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_best_move\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m game\u001b[38;5;241m.\u001b[39mrotate(rot)\n\u001b[0;32m    100\u001b[0m game\u001b[38;5;241m.\u001b[39mgo_side(col)\n",
      "File \u001b[1;32m~\\Desktop\\Tetris\\learning_tetris\\game_code\\game_simulation.py:79\u001b[0m, in \u001b[0;36mevaluate_best_move\u001b[1;34m(W, field, type)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m game_copy\u001b[38;5;241m.\u001b[39mintersects():\n\u001b[0;32m     78\u001b[0m             game_copy\u001b[38;5;241m.\u001b[39mgo_space()\n\u001b[1;32m---> 79\u001b[0m             score\u001b[38;5;241m.\u001b[39mappend(\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgame_copy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     80\u001b[0m             L\u001b[38;5;241m.\u001b[39mappend((col,k))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(L)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Desktop\\Tetris\\learning_tetris\\game_code\\game_simulation.py:49\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(W, field)\u001b[0m\n\u001b[0;32m     47\u001b[0m h\u001b[38;5;241m=\u001b[39mcolumn_height(field)\n\u001b[0;32m     48\u001b[0m dh\u001b[38;5;241m=\u001b[39mcolumn_difference(field)\n\u001b[1;32m---> 49\u001b[0m L\u001b[38;5;241m=\u001b[39m\u001b[43mholes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m H\u001b[38;5;241m=\u001b[39mmaximum_height(field)\n\u001b[0;32m     51\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\Tetris\\learning_tetris\\game_code\\game_simulation.py:38\u001b[0m, in \u001b[0;36mholes\u001b[1;34m(field)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mholes\u001b[39m(field):\n\u001b[0;32m     37\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m     h  \u001b[38;5;241m=\u001b[39m\u001b[43mcolumn_height\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m\u001b[38;5;241m-\u001b[39mh[j],\u001b[38;5;241m20\u001b[39m):\n",
      "File \u001b[1;32m~\\Desktop\\Tetris\\learning_tetris\\game_code\\game_simulation.py:18\u001b[0m, in \u001b[0;36mcolumn_height\u001b[1;34m(field)\u001b[0m\n\u001b[0;32m     16\u001b[0m h \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 18\u001b[0m     column \u001b[38;5;241m=\u001b[39m [field[i][j] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m)]\n\u001b[0;32m     19\u001b[0m     height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m height \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m column[height] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def simulation_SA(N_iteration, step_size, temp):\n",
    "    learning_curve = []\n",
    "    \n",
    "    s0 = np.random.multivariate_normal(np.zeros(21), 100*np.eye(21))\n",
    "    best_score = simulation(s0)\n",
    "\n",
    "\n",
    "    for i in range(N_iteration):\n",
    "        neighbour = s0 + np.random.multivariate_normal(np.zeros(21), np.eye(21))*step_size\n",
    "        score_neighbour = simulation(neighbour)\n",
    "        \n",
    "        delta = score_neighbour - best_score\n",
    "        if delta > 0:\n",
    "            s0, best_score = neighbour, score_neighbour\n",
    "        else:\n",
    "            t = temp / float(i+1)\n",
    "            metropolis = exp(delta/t)\n",
    "            if np.random.rand() < metropolis:\n",
    "                s0, best_score = neighbour, score_neighbour\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        learning_curve.append(best_score)\n",
    "        print(\"Iteration {}: score : {}\".format(i+1, learning_curve[-1]))\n",
    "    \n",
    "    return learning_curve\n",
    "\n",
    "\n",
    "print(simulation_SA(1000, 20, 20))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the algorithm became longer to converge, albeit simpler, efforts were made to enhance its performance by selecting a sample as both the current solution and the neighbor, instead of a single point. Furthermore, akin to the cross-entropy method, parameters of the distributions are updated with those of the best-performing samples in terms of score. This adaptation facilitates faster convergence.\n",
    "\n",
    "Here is an implimentation of our enhanced simulated annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SA(cooling, n_iteration, n_samples, rho):\n",
    "\n",
    "    mean = np.zeros(21)\n",
    "    cov = 100 * np.eye(21)\n",
    "    learning_curve = []\n",
    "    T = 100 # Initial Temperature\n",
    "    \n",
    "    for j in range(n_iteration):\n",
    "        s0 = np.random.multivariate_normal(mean, cov, n_samples)\n",
    "        s_neighbour = s0 + np.random.multivariate_normal(np.zeros(21), 50*np.eye(21), n_samples)\n",
    "        scores = [simulation(sample) for sample in s0]\n",
    "        scores_neighbour = [simulation(sample) for sample in s_neighbour]\n",
    "\n",
    "        best_indexes = np.argsort(scores)[-int(n_samples * rho):]\n",
    "        best_samples = s0[best_indexes]\n",
    "        best_scores = np.array(scores)[best_indexes]\n",
    "\n",
    "        best_indexes = np.argsort(scores_neighbour)[-int(n_samples * rho):]\n",
    "        best_neighbours = s_neighbour[best_indexes]\n",
    "        best_scores_neighbour = np.array(scores_neighbour)[best_indexes]\n",
    "\n",
    "        theta = np.mean(best_scores) - np.mean(best_scores_neighbour)\n",
    "        if theta < 0:\n",
    "            s0 = s_neighbour\n",
    "            best_samples = best_neighbours\n",
    "        else:\n",
    "            p = exp(-theta/T)\n",
    "            u = np.random.random()\n",
    "            if u < p:\n",
    "                s0 = s_neighbour\n",
    "                best_samples = best_neighbours\n",
    "\n",
    "        mean = np.mean(best_samples, axis = 0)\n",
    "        cov =  np.cov(best_samples, rowvar = False, bias=True)\n",
    "\n",
    "    \n",
    "\n",
    "        test_scores = []\n",
    "        for _ in range(30):\n",
    "            test_scores.append(simulation(mean))\n",
    "\n",
    "        learning_curve.append(np.mean(test_scores))\n",
    "        print(\"Iteration {}: Average score : {}\".format(j+1, learning_curve[-1]))\n",
    "\n",
    "\n",
    "        T *= cooling\n",
    "        \n",
    "    return(learning_curve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Average score : 10.1\n",
      "Iteration 2: Average score : 17.733333333333334\n",
      "Iteration 3: Average score : 20.4\n",
      "Iteration 4: Average score : 24.666666666666668\n",
      "Iteration 5: Average score : 54.2\n",
      "Iteration 6: Average score : 52.53333333333333\n",
      "Iteration 7: Average score : 64.03333333333333\n",
      "Iteration 8: Average score : 65.96666666666667\n",
      "Iteration 9: Average score : 83.46666666666667\n",
      "Iteration 10: Average score : 85.43333333333334\n",
      "Iteration 11: Average score : 83.6\n",
      "Iteration 12: Average score : 97.16666666666667\n",
      "Iteration 13: Average score : 78.03333333333333\n",
      "Iteration 14: Average score : 82.3\n",
      "Iteration 15: Average score : 84.43333333333334\n",
      "Iteration 16: Average score : 120.7\n",
      "Iteration 17: Average score : 138.9\n",
      "Iteration 18: Average score : 151.66666666666666\n",
      "Iteration 19: Average score : 164.63333333333333\n",
      "Iteration 20: Average score : 154.1\n",
      "Iteration 21: Average score : 145.9\n",
      "Iteration 22: Average score : 147.46666666666667\n",
      "Iteration 23: Average score : 138.5\n",
      "Iteration 24: Average score : 177.46666666666667\n",
      "Iteration 25: Average score : 156.13333333333333\n",
      "Iteration 26: Average score : 188.43333333333334\n",
      "Iteration 27: Average score : 193.2\n",
      "Iteration 28: Average score : 178.86666666666667\n",
      "Iteration 29: Average score : 185.66666666666666\n",
      "Iteration 30: Average score : 170.66666666666666\n",
      "Iteration 31: Average score : 166.46666666666667\n",
      "Iteration 32: Average score : 175.3\n",
      "Iteration 33: Average score : 158.43333333333334\n",
      "Iteration 34: Average score : 204.86666666666667\n",
      "Iteration 35: Average score : 141.56666666666666\n",
      "Iteration 36: Average score : 212.76666666666668\n",
      "Iteration 37: Average score : 219.03333333333333\n",
      "Iteration 38: Average score : 166.3\n",
      "Iteration 39: Average score : 192.56666666666666\n",
      "Iteration 40: Average score : 211.73333333333332\n"
     ]
    }
   ],
   "source": [
    "curve = SA(.5, 50, 100, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [10.1,\n",
    "17.733333333333334,\n",
    "20.4,\n",
    "24.666666666666668,\n",
    "54.2,\t\t\t\n",
    "52.53333333333333,\n",
    "64.03333333333333,\n",
    "65.96666666666667,\n",
    "83.46666666666667,\n",
    "85.43333333333334,\n",
    "83.6,\t\t\t\n",
    "97.16666666666667,\n",
    "78.03333333333333,\n",
    "82.3,\n",
    "84.43333333333334,\n",
    "120.7,\n",
    "138.9,\t\t\t\n",
    "151.66666666666666,\n",
    "164.63333333333333,\n",
    "154.1,\n",
    "145.9,\t\t\t\n",
    "147.46666666666667,\n",
    "138.5,\t\t\t\n",
    "177.46666666666667,\n",
    "156.13333333333333,\n",
    "188.43333333333334,\n",
    "193.2,\t\t\t\n",
    "178.86666666666667,\n",
    "185.66666666666666,\n",
    "170.66666666666666,\n",
    "166.46666666666667,\n",
    "175.3,\n",
    "158.43333333333334,\n",
    "204.86666666666667,\n",
    "212.76666666666668,\n",
    "219.03333333333333,\n",
    "166.3,\n",
    "211.73333333333332]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(range(1,16), results, fmt='o', capsize=5)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Average Score')\n",
    "plt.title('Learning Curve with Somulated Annealing')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
